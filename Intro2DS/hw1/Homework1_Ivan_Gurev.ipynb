{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fengSNSWl1X"
   },
   "source": [
    "# Assignment 1. Traffic volume prediction.\n",
    "by Anvar Kurmukov,\n",
    "updated by Bogdan Kirillov, Hekmat Taherinejad, Satyarth Mishra Sharma\n",
    "\n",
    "---\n",
    "\n",
    "By the end of this task you will be able to manipulate huge tabular data:\n",
    "1. Compute different column's statistics (min, max, mean, quantiles etc.);\n",
    "2. Select observations/features by condition/index;\n",
    "3. Create new non-linear combinations of the columns (feature engineering);\n",
    "4. Perform automated data cleaning;\n",
    "\n",
    "and more.\n",
    "\n",
    "---\n",
    "\n",
    "For those who are not familiar with `pandas` we recommend these (alternative) tutorials:\n",
    "\n",
    "1. Single notebook, covers basic pandas functionality (starting with renaming columns ending with using map, apply etc) ~ 30 short examples with links on videos https://nbviewer.jupyter.org/github/justmarkham/pandas-videos/blob/master/pandas.ipynb . Highly recommended for everyone. (about 1-3 hours to go through)\n",
    "\n",
    "2. https://github.com/guipsamora/pandas_exercises/ 11 topics covering all essential functionality with excersises (with solutions).\n",
    "\n",
    "This task will be an easy ride after these tutorials.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBv4L3BoWtY8"
   },
   "source": [
    "We are using a public dataset compiling weather information and traffic data continuously monitored in the Twin Cities, Minnesota from 2012 to 2018. The dataset page can be found [here](https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume). We've slightly modified it so please download the dataset provided on Canvas.  \n",
    "\n",
    "You need to download `Metro_Interstate_Traffic_Volume.csv` and place it in the same directory as this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rYmsZ_BQWx6a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mp5vQW5Xtw5"
   },
   "source": [
    "# 1. Loading data\n",
    "\n",
    "As always in Data Science you are starting with making nice cup of tea (or coffee). Your next move is to load the data:\n",
    "\n",
    "- Start with loading `Metro_Interstate_Traffic_Volume.csv` file using `pd.read_csv()` function.\n",
    "- You may also want to increase maximal displayed pandas columns: set `pd.options.display.max_columns` to 30\n",
    "- Print top 10 observations in the table. `.head()`\n",
    "- Print last 10 observations in the table. `.tail()`\n",
    "- Print all the data columns names using method `.columns`\n",
    "- Print data size (number of rows and columns). This is the `.shape` of the data.\n",
    "\n",
    "*Almost* every python has a `head` and a `tail` just as DataFrames do.\n",
    "\n",
    "If you are using Google Colab, you can upload the file in the cell below. If you are NOT using Colab, set COLAB_P in the cell below to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "id": "KS_2J7IXX9ZS",
    "outputId": "6a5a75dd-4245-4992-8c2b-20275dceb5cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place your file to the same directory as the notebook, then read your file with pd.read_csv()\n"
     ]
    }
   ],
   "source": [
    "COLAB_P = False\n",
    "if COLAB_P:\n",
    "    print(\"Upload your file, then read it with pd.read_csv()\")\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    fn = list(uploaded.keys())[0]\n",
    "    print(\"File is uploaded to \", fn)\n",
    "else:\n",
    "    print(\"Place your file to the same directory as the notebook, then read your file with pd.read_csv()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IMsqdgKrYugR"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "db = pd.read_csv(\"Metro_Interstate_Traffic_volume.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "H0P12NdQZPxw",
    "outputId": "dc794a4e-c50f-408e-a284-a130a70d2dda"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>date_time</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>288.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>2012-10-02 09:00:00</td>\n",
       "      <td>5545.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>289.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2012-10-02 10:00:00</td>\n",
       "      <td>4516.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>289.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2012-10-02 11:00:00</td>\n",
       "      <td>4767.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>290.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2012-10-02 12:00:00</td>\n",
       "      <td>5026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>291.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2012-10-02 13:00:00</td>\n",
       "      <td>4918.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>291.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>2012-10-02 14:00:00</td>\n",
       "      <td>5181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>293.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>2012-10-02 15:00:00</td>\n",
       "      <td>5584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>293.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>2012-10-02 16:00:00</td>\n",
       "      <td>6015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>294.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>2012-10-02 17:00:00</td>\n",
       "      <td>5791.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>293.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>2012-10-02 18:00:00</td>\n",
       "      <td>4770.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  holiday    temp  rain_1h  snow_1h  clouds_all weather_main  \\\n",
       "0    None  288.28      0.0      0.0        40.0       Clouds   \n",
       "1    None  289.36      0.0      0.0        75.0       Clouds   \n",
       "2    None  289.58      0.0      0.0        90.0       Clouds   \n",
       "3    None  290.13      0.0      0.0        90.0       Clouds   \n",
       "4    None  291.14      0.0      0.0        75.0       Clouds   \n",
       "5    None  291.72      0.0      0.0         1.0        Clear   \n",
       "6    None  293.17      0.0      0.0         1.0        Clear   \n",
       "7    None  293.86      0.0      0.0         1.0        Clear   \n",
       "8    None  294.14      0.0      0.0        20.0       Clouds   \n",
       "9    None  293.10      0.0      0.0        20.0       Clouds   \n",
       "\n",
       "  weather_description            date_time  traffic_volume  \n",
       "0    scattered clouds  2012-10-02 09:00:00          5545.0  \n",
       "1       broken clouds  2012-10-02 10:00:00          4516.0  \n",
       "2     overcast clouds  2012-10-02 11:00:00          4767.0  \n",
       "3     overcast clouds  2012-10-02 12:00:00          5026.0  \n",
       "4       broken clouds  2012-10-02 13:00:00          4918.0  \n",
       "5        sky is clear  2012-10-02 14:00:00          5181.0  \n",
       "6        sky is clear  2012-10-02 15:00:00          5584.0  \n",
       "7        sky is clear  2012-10-02 16:00:00          6015.0  \n",
       "8          few clouds  2012-10-02 17:00:00          5791.0  \n",
       "9          few clouds  2012-10-02 18:00:00          4770.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observe top 10 observations (int)\n",
    "db.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "MXEj8wifdVjV",
    "outputId": "2c48f70b-b389-49bb-a9f3-3a506cbaa51f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>date_time</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48194</th>\n",
       "      <td>None</td>\n",
       "      <td>283.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Rain</td>\n",
       "      <td>proximity shower rain</td>\n",
       "      <td>2018-09-30 15:00:00</td>\n",
       "      <td>4302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48195</th>\n",
       "      <td>None</td>\n",
       "      <td>283.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Drizzle</td>\n",
       "      <td>light intensity drizzle</td>\n",
       "      <td>2018-09-30 15:00:00</td>\n",
       "      <td>4302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48196</th>\n",
       "      <td>None</td>\n",
       "      <td>284.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Rain</td>\n",
       "      <td>light rain</td>\n",
       "      <td>2018-09-30 16:00:00</td>\n",
       "      <td>4283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48197</th>\n",
       "      <td>None</td>\n",
       "      <td>284.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2018-09-30 17:00:00</td>\n",
       "      <td>4132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48198</th>\n",
       "      <td>None</td>\n",
       "      <td>284.20</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Rain</td>\n",
       "      <td>light rain</td>\n",
       "      <td>2018-09-30 18:00:00</td>\n",
       "      <td>3947.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48199</th>\n",
       "      <td>None</td>\n",
       "      <td>283.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>2018-09-30 19:00:00</td>\n",
       "      <td>3543.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48200</th>\n",
       "      <td>None</td>\n",
       "      <td>282.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2018-09-30 20:00:00</td>\n",
       "      <td>2781.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48201</th>\n",
       "      <td>None</td>\n",
       "      <td>282.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Thunderstorm</td>\n",
       "      <td>proximity thunderstorm</td>\n",
       "      <td>2018-09-30 21:00:00</td>\n",
       "      <td>2159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48202</th>\n",
       "      <td>None</td>\n",
       "      <td>282.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2018-09-30 22:00:00</td>\n",
       "      <td>1450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48203</th>\n",
       "      <td>None</td>\n",
       "      <td>282.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>2018-09-30 23:00:00</td>\n",
       "      <td>954.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      holiday    temp  rain_1h  snow_1h  clouds_all  weather_main  \\\n",
       "48194    None  283.84     0.00      0.0        75.0          Rain   \n",
       "48195    None  283.84     0.00      0.0        75.0       Drizzle   \n",
       "48196    None  284.38     0.00      0.0        75.0          Rain   \n",
       "48197    None  284.79     0.00      0.0        75.0        Clouds   \n",
       "48198    None  284.20     0.25      0.0        75.0          Rain   \n",
       "48199    None  283.45     0.00      0.0        75.0        Clouds   \n",
       "48200    None  282.76     0.00      0.0        90.0        Clouds   \n",
       "48201    None  282.73     0.00      0.0        90.0  Thunderstorm   \n",
       "48202    None  282.09     0.00      0.0        90.0        Clouds   \n",
       "48203    None  282.12     0.00      0.0        90.0        Clouds   \n",
       "\n",
       "           weather_description            date_time  traffic_volume  \n",
       "48194    proximity shower rain  2018-09-30 15:00:00          4302.0  \n",
       "48195  light intensity drizzle  2018-09-30 15:00:00          4302.0  \n",
       "48196               light rain  2018-09-30 16:00:00          4283.0  \n",
       "48197            broken clouds  2018-09-30 17:00:00          4132.0  \n",
       "48198               light rain  2018-09-30 18:00:00          3947.0  \n",
       "48199            broken clouds  2018-09-30 19:00:00          3543.0  \n",
       "48200          overcast clouds  2018-09-30 20:00:00          2781.0  \n",
       "48201   proximity thunderstorm  2018-09-30 21:00:00          2159.0  \n",
       "48202          overcast clouds  2018-09-30 22:00:00          1450.0  \n",
       "48203          overcast clouds  2018-09-30 23:00:00           954.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observe last 10 observations (int)\n",
    "db.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zui3i6ZOdo2D",
    "outputId": "afbc65c8-ee84-4325-d5c0-9ff307c78f68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: \n",
      "holiday, temp, rain_1h, snow_1h, clouds_all, weather_main, weather_description, date_time, traffic_volume\n"
     ]
    }
   ],
   "source": [
    "# Print all the columns/features names (int)\n",
    "features = db.columns\n",
    "print('Features: ')\n",
    "print(*features, sep = ', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QwPaHlDhuklP",
    "outputId": "b49a1252-f5be-4b1c-be5c-d048af3375d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1.1 How many columns end with a vowel? 2\n",
      "# Q1.2 How many columns start with a vowel? 0\n",
      "# Q1.4 How many columns have `th` in their names? 2\n"
     ]
    }
   ],
   "source": [
    "def CountVowel(words,position):\n",
    "    \"\"\"\n",
    "    words is an array of strings\n",
    "    position is a position of vowel in a string\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    vowels = ['a','e','u','i','o']\n",
    "    \n",
    "    for word in words:\n",
    "        if word[position] in vowels:\n",
    "            counter += 1\n",
    "    return counter\n",
    "\n",
    "# Q1.1 How many columns end with a vowel?\n",
    "print('Q1.1 How many columns end with a vowel?', CountVowel(features,-1))\n",
    "    \n",
    "# Q1.2 How many columns start with a vowel?\n",
    "print('# Q1.2 How many columns start with a vowel?', CountVowel(features,0))\n",
    "\n",
    "# Q1.3 Which columns are associated with the condition of weather?\n",
    "\n",
    "\n",
    "# Q1.4 How many columns have `th` in their names?\n",
    "def FindCombination(words, combination):\n",
    "    \"\"\"\n",
    "    words is an array of strings\n",
    "    combination is a string to find\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    \n",
    "    for word in words:\n",
    "        if combination in word:\n",
    "            counter += 1\n",
    "    return counter\n",
    "\n",
    "print('# Q1.4 How many columns have `th` in their names?', FindCombination(features,'th'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ka8e4hmZdqLp",
    "outputId": "fefb08cc-d966-465a-ef55-cb5410f50b43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print data size (48204, 9)\n",
      "Q2.1 How many observations are in the data? 48204\n",
      "Q2.2 How many features are in the data? 9\n"
     ]
    }
   ],
   "source": [
    "# Print data size (int)\n",
    "print('Print data size',db.shape)\n",
    "\n",
    "# Q2.1 How many observations are in the data?\n",
    "print('Q2.1 How many observations are in the data?',db.shape[0])\n",
    "\n",
    "# Q2.2 How many features are in the data?\n",
    "print('Q2.2 How many features are in the data?',db.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWqFpMWPdy3E"
   },
   "source": [
    "# 2. Basic data exploration\n",
    "\n",
    "Lets do some basics:\n",
    "\n",
    "`.count()` number of not NaN's in every column.\n",
    "    \n",
    "Is there any missing values in the data?     \n",
    "Count number of unique values in every column .nunique().    \n",
    "What does this tells you about the features, which are most likely categorical and which are most likely numerical?    \n",
    "Use pandas `.describe()` to display basic statistic about the data.   \n",
    "Use pandas `.value_counts()` to count number of unique values in a specific column.   \n",
    "Use pandas `.min()`, `.max()`, `.mean()`, `.std()` to display specific statistics about the data.    \n",
    "Use pandas `.dtypes` field to display data types in columns. \n",
    "Hint You could use `.sort_index()` or `.sort_values()` to sort the result of `.value_counts()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pwlcBdvIwlfB",
    "outputId": "1471393c-97aa-437d-ce98-377d5d62556e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display number of not NaNs in every column\n",
      "holiday                48204\n",
      "temp                   48203\n",
      "rain_1h                48203\n",
      "snow_1h                48204\n",
      "clouds_all             48201\n",
      "weather_main           48203\n",
      "weather_description    48201\n",
      "date_time              48204\n",
      "traffic_volume         48199\n",
      "dtype: int64\n",
      " \n",
      "Q3.2 How many NA values are in the `temp` column? 1 \n",
      "\n",
      "Q3.5 How many explicit NA values are in the `traffic_volume` column? 5\n"
     ]
    }
   ],
   "source": [
    "# Display number of not NaN's in every column (int)\n",
    "print('Display number of not NaNs in every column',db.count(), ' ', sep = '\\n')\n",
    "\n",
    "# Q3.2 How many NA values are in the `temp` column?\n",
    "print('Q3.2 How many NA values are in the `temp` column?',db['temp'].isna().sum(), '\\n')\n",
    "\n",
    "# Q3.5 How many explicit NA values are in the `traffic_volume` column?\n",
    "print('Q3.5 How many explicit NA values are in the `traffic_volume` column?', db['traffic_volume'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now drop rows with NaN with `.dropna`. Remeber to either reassign your dataframe or provide `inplace=True` argument.\n",
    "db.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "bo6KibQ3x4Jw",
    "outputId": "55e2f0a4-7591-4829-dc61-25b645d56487"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48190.000000</td>\n",
       "      <td>48190.000000</td>\n",
       "      <td>48190.000000</td>\n",
       "      <td>48190.000000</td>\n",
       "      <td>48190.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.201366</td>\n",
       "      <td>0.334356</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>49.369267</td>\n",
       "      <td>3259.859079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.337406</td>\n",
       "      <td>44.795638</td>\n",
       "      <td>0.008169</td>\n",
       "      <td>39.016127</td>\n",
       "      <td>1986.972809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>272.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1192.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>282.440000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>3380.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>291.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>4933.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>310.070000</td>\n",
       "      <td>9831.300000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>7280.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               temp       rain_1h       snow_1h    clouds_all  traffic_volume\n",
       "count  48190.000000  48190.000000  48190.000000  48190.000000    48190.000000\n",
       "mean     281.201366      0.334356      0.000222     49.369267     3259.859079\n",
       "std       13.337406     44.795638      0.008169     39.016127     1986.972809\n",
       "min        0.000000      0.000000      0.000000      0.000000        0.000000\n",
       "25%      272.160000      0.000000      0.000000      1.000000     1192.250000\n",
       "50%      282.440000      0.000000      0.000000     64.000000     3380.000000\n",
       "75%      291.800000      0.000000      0.000000     90.000000     4933.000000\n",
       "max      310.070000   9831.300000      0.510000    100.000000     7280.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display basic data statistics using .describe()\n",
    "db.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uCxMUIbnx-QD",
    "outputId": "0232e59d-e775-4118-ce07-cb94a96b5b60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count number of unique values in every column\n",
      "holiday                   12\n",
      "temp                    5843\n",
      "rain_1h                  372\n",
      "snow_1h                   12\n",
      "clouds_all                60\n",
      "weather_main              11\n",
      "weather_description       38\n",
      "date_time              40562\n",
      "traffic_volume          6704\n",
      "dtype: int64\n",
      " \n",
      "Q4.4 How many unique values are in the `snow_1h` column? 12 \n",
      "\n",
      "Q4.5 How many unique values are in the `rain_1h` column? 372\n"
     ]
    }
   ],
   "source": [
    "# Count number of unique values in every column (int)\n",
    "print('Count number of unique values in every column', db[features].nunique(), ' ', sep = '\\n',)\n",
    "\n",
    "# Q4.4 How many unique values are in the `snow_1h` column?\n",
    "print('Q4.4 How many unique values are in the `snow_1h` column?', db['snow_1h'].nunique(),'\\n')\n",
    "\n",
    "# Q4.5 How many unique values are in the `rain_1h` column?\n",
    "print('Q4.5 How many unique values are in the `rain_1h` column?', db['rain_1h'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fPJMcqYQyD9y",
    "outputId": "d1ba998f-0b2b-469d-c6f0-0304fcb5a3f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of occurences of unique values in weather_main: 4 20 912 1034 1359 1821 2876 5671 5950 13384 15159\n",
      "\n",
      " number of occurences of unique values in weather_description:  [    1     2     2     3     4     6     6    11    13    13    15    18\n",
      "    20    37    52    54    63    64   125   136   293   467   616   651\n",
      "   673   912  1100  1359  1664  1726  1946  1955  3371  3458  4665  5081\n",
      "  5950 11658]\n"
     ]
    }
   ],
   "source": [
    "# Count frequency of the values in different columns (list of ints in ascending order)\n",
    "\n",
    "# You could select a column using same syntax as for selecting a key from a dictionary: `data[colname]`\n",
    "# numpy's `unique` function can be useful for this task\n",
    "\n",
    "# Q5.1 For every unique `weather_main` value give its number of occurences.\n",
    "a = np.sort(db['weather_main'].value_counts().values)\n",
    "print('number of occurences of unique values in weather_main:', *a, sep = ' ')\n",
    "b = np.sort(db['weather_description'].value_counts().values)\n",
    "# Q5.2 For every unique `weather_description` value give its number of occurences.\n",
    "print('\\n','number of occurences of unique values in weather_description: ', b, sep = ' ',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9vIOZuv7yErp",
    "outputId": "11c3fdb7-d4bc-4ad2-f059-d4ac01492e2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q6.1 What are the max, min, mean and the std of the `traffic_volume` column?\n",
      " max     7280.000\n",
      "min        0.000\n",
      "mean    3259.859\n",
      "std     1986.973\n",
      "Name: traffic_volume, dtype: float64 \n",
      "\n",
      "Q6.2 What are the max, min, mean and the std of the `clouds_all` column?\n",
      " max     100.000\n",
      "min       0.000\n",
      "mean     49.369\n",
      "std      39.016\n",
      "Name: clouds_all, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Display some column statistics (list of floats, rounded up to 3 digits, e.g. 1.234)\n",
    "stats = ['max','min','mean','std']\n",
    "\n",
    "# Q6.1 What are the max, min, mean and the std of the `traffic_volume` column?\n",
    "print('Q6.1 What are the max, min, mean and the std of the `traffic_volume` column?\\n',db['traffic_volume'].describe()[stats].apply(lambda x: round(x,3)),'\\n')\n",
    "\n",
    "# Q6.2 What are the max, min, mean and the std of the `clouds_all` column?\n",
    "print('Q6.2 What are the max, min, mean and the std of the `clouds_all` column?\\n',db['clouds_all'].describe()[stats].apply(lambda x: round(x,3)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71Kx1GnoyG7v",
    "outputId": "4748f2d3-ca71-45e7-8438-728672463e43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holiday                 object\n",
      "temp                   float64\n",
      "rain_1h                float64\n",
      "snow_1h                float64\n",
      "clouds_all             float64\n",
      "weather_main            object\n",
      "weather_description     object\n",
      "date_time               object\n",
      "traffic_volume         float64\n",
      "dtype: object \n",
      "\n",
      "Q7.1 How many columns have `object` data type? 4 \n",
      "\n",
      "Q7.3 How many columns have `float64` data type? 5\n"
     ]
    }
   ],
   "source": [
    "# Display data types of all columns (int)\n",
    "print(db.dtypes, '\\n')\n",
    "\n",
    "# Q7.1 How many columns have `object` data type?\n",
    "print('Q7.1 How many columns have `object` data type?',  (db.dtypes == 'object').sum(), '\\n')\n",
    "\n",
    "# Q7.3 How many columns have `float64` data type?\n",
    "print('Q7.3 How many columns have `float64` data type?',  (db.dtypes == 'float64').sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rrG2dQQe5yf"
   },
   "source": [
    "# 3. Data selection\n",
    "\n",
    "In pandas.DataFrame you could select\n",
    "\n",
    "  Row/s by position (integer number [0 .. number of rows - 1]) .iloc or by DataFrame.index .loc:   \n",
    "\n",
    "```\n",
    "  data.loc[0]  \n",
    "  data.loc[5:10]  \n",
    "  data.iloc[0]  \n",
    "  data.iloc[5:10]   \n",
    "```\n",
    "\n",
    "Though, this is probably the worst way to manipulate rows.   \n",
    "  Columns by name\n",
    "\n",
    "```\n",
    "  data[columname]\n",
    "```\n",
    "\n",
    "  Row/s and columns\n",
    "\n",
    "```\n",
    "  data.loc[10, columname]  \n",
    "  data.iloc[10, columname]  \n",
    "```\n",
    "\n",
    "Using boolean mask\n",
    "\n",
    "```\n",
    "  mask = data[columname] > value  \n",
    "  data[mask]  \n",
    "```\n",
    "\n",
    "You could combine multiple conditions using & or | (and, or)   \n",
    "\n",
    "```\n",
    "cond1 = data[columname1] > value1  \n",
    "cond2 = data[columname2] > value2  \n",
    "data[cond1 & cond2]  \n",
    "```\n",
    "\n",
    "Using queries .query():  \n",
    "\n",
    "```\n",
    "value = 5 \n",
    "data.query(\"columname > value\")  \n",
    "```\n",
    "\n",
    "You could combine multiple conditions using and, or  \n",
    "\n",
    "```\n",
    "data.query(\"(columname1 > value1) and (columname2 > value2)\")\n",
    "```\n",
    "\n",
    "and others. See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html for more examples.\n",
    "\n",
    "Remember to use different quotation marks \" or ' for columnname inside a query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WJnCqUx-0YRx",
    "outputId": "0be7619b-9aa3-417c-a1b0-eb4579164d28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q8.2 What is the weather description of the time slot with index 999? overcast clouds\n",
      "Q8.4 What is the weather main of the time slot with index 314? Clouds\n"
     ]
    }
   ],
   "source": [
    "# Select rows by position (int) \n",
    "\n",
    "# Q8.2 What is the weather description of the time slot with index 999?\n",
    "print('Q8.2 What is the weather description of the time slot with index 999?',db.loc[999,'weather_description'])\n",
    "\n",
    "# Q8.4 What is the weather main of the time slot with index 314?\n",
    "print('Q8.4 What is the weather main of the time slot with index 314?',db.loc[314,'weather_main'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nv5jRoeU0aQG",
    "outputId": "635a0c74-7039-40cc-a391-5b31c8823419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q9.3 How much is cloud coverage on the index 1045? 20.0\n",
      "Q9.5 When was the time slot with index of 38 captured? 2012-10-04 03:00:00\n"
     ]
    }
   ],
   "source": [
    "# Select rows by index (int)\n",
    "\n",
    "# Q9.3 How much is cloud coverage on the index 1045?\n",
    "print('Q9.3 How much is cloud coverage on the index 1045?',db.iloc[1045]['clouds_all'])\n",
    "\n",
    "# Q9.5 When was the time slot with index of 38 captured?\n",
    "print('Q9.5 When was the time slot with index of 38 captured?',db.iloc[38]['date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZneqD6P0e5C",
    "outputId": "e0a1552e-7042-4ead-eb0a-75cf9a213ea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q10.1 How many time slots have less than 270 temperature? 9308\n",
      "Q10.4 How many time slots are foggy? (weather_main = Fog) 912\n"
     ]
    }
   ],
   "source": [
    "# Using mask or .query syntax select rows/columns (int)\n",
    "\n",
    "# Q10.1 How many time slots have less than 270 temperature?\n",
    "print('Q10.1 How many time slots have less than 270 temperature?',db[db['temp']<270].shape[0])\n",
    "\n",
    "# Q10.4 How many time slots are foggy? (weather_main = Fog)\n",
    "print('Q10.4 How many time slots are foggy? (weather_main = Fog)',db[db['weather_main'] == 'Fog'].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q11.1 What is the traffic volume of November 20th 2016, at 20:00? 2070.0 \n",
      "\n",
      "Q11.3 How much cloud coverage percentage were in sky on October 16th 2012 at 19:00? 68.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q11.1 What is the traffic volume of November 20th 2016, at 20:00?\n",
    "print('Q11.1 What is the traffic volume of November 20th 2016, at 20:00?',db[db['date_time']=='2016-11-20 20:00:00']['traffic_volume'].values[0],'\\n')\n",
    "\n",
    "# Q11.3 How much cloud coverage percentage were in sky on October 16th 2012 at 19:00?\n",
    "print('Q11.3 How much cloud coverage percentage were in sky on October 16th 2012 at 19:00?',db[db['date_time']=='2012-10-16 19:00:00']['clouds_all'].values[0],'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q12.2 What is the traffic volume for 99-th time slot with cloud coverage 75 percent? 762.0\n",
      "Q12.5 What is the temperature of 1337-th time slot with clear sky (clouds_all <= 20)? 277.06\n"
     ]
    }
   ],
   "source": [
    "# Q12.2 What is the traffic volume for 99-th time slot with cloud coverage 75 percent? \n",
    "print('Q12.2 What is the traffic volume for 99-th time slot with cloud coverage 75 percent?',db[db['clouds_all']==75].iloc[99]['traffic_volume'])\n",
    "\n",
    "# Q12.5 What is the temperature of 1337-th time slot with clear sky (clouds_all <= 20)?\n",
    "print('Q12.5 What is the temperature of 1337-th time slot with clear sky (clouds_all <= 20)?',db[db['clouds_all']<=20].iloc[1337]['temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "nxbj9Po2Le18",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create new columns using the old ones (new column in your DataFrame)\n",
    "\n",
    "# Q13.1 Create a `temp_in_celcius` column from the existing `temp` (kelvin) using any method above\n",
    "db['temp_in_celcius'] = db['temp']-273.15 #Is it data from Venus? temp ~ 500 C is really hot, btw\n",
    "\n",
    "# Q13.2 Create a new bool column `hot` which indicates whether the time slot was hot (temp > 300)\n",
    "db['hot'] = db['temp']>300\n",
    "\n",
    "# Q13.3 Create a new bool column `rainy_and_cloudy` which indicates whether it was rainy (>0.1) AND cloudy (>50)\n",
    "db['rainly_and_cloudy'] = (db['clouds_all']>50) & (db['rain_1h']>0.1)\n",
    "\n",
    "# Q13.4 Create a new bool column `is_holiday` which indicates whether the day of the time slot falls on any holiday\n",
    "db['is_holiday'] = (db['holiday'] != \"None\")\n",
    "\n",
    "# Q13.5 Create a new column `traffic_cat` by splitting a `traffic_volume` into 5 ([1..5]) distinct intervals: 0 < x <=20%,\n",
    "# 20% < x <= 40%, ... 80% < x <= 100% percentiles. You could use `.quantile()` to compute percentiles.\n",
    "db['traffic_cat'] = pd.qcut(db['traffic_volume'], q = [0,0.2,0.4,0.6,0.8,1], labels =[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "db['date'] = pd.to_datetime(db['date_time']).dt.date\n",
    "db['is_holiday'] = db['date'].map(db[db['holiday'] != 'None'].groupby('date')['holiday'].min())\n",
    "db['is_holiday'] = db.is_holiday.notna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBLabnN2fAPc"
   },
   "source": [
    "5# 4. Creating new columns\n",
    "\n",
    "Creating new column of pandas.DataFrame is as easy as:\n",
    "```\n",
    "data['new_awesome_column'] = [] \n",
    "```\n",
    "that's it. But such a column is relatively useless. Typically, you would compute something new based on existing data and save it in a new column. For example one might want to sum a number of existing columns:\n",
    "```\n",
    "data['sum'] = data[col1] + data[col2] + ...\n",
    "```\n",
    "Pandas also provides another powerfull tool: .apply, .map(), .applymap() methods (they are kinda the same, but not quite). https://stackoverflow.com/questions/19798153/difference-between-map-applymap-and-apply-methods-in-pandas . They allow you to apply some function to every value in the column/s (row-wise) or row (column-wise) or cell (element-wise). For example, same computations of sum using .apply():\n",
    "```\n",
    "data['sum'] = data[[col1, col2, col3]].apply(sum, axis=1)\n",
    "```\n",
    "you are not restricted to existent functions, .apply() accepts any function (including lambda functions):\n",
    "```\n",
    "data['sum'] = data[[col1, col2, col3]].apply(lambda x: x[0]+x[1]+x[2], axis=1)\n",
    "```\n",
    "or ordinary python function (if this it should have complex behaviour):\n",
    "```\n",
    "def _sum(x):\n",
    "    total = 0\n",
    "    for elem in x:\n",
    "        total += elem\n",
    "    return total\n",
    "\n",
    "data['sum'] = data[[col1, col2, col3]].apply(_sum, axis=1) \n",
    "```\n",
    "Many pandas methods has axis parameter axis=0 refers to rows, axis=1 refers to columns.\n",
    "\n",
    "Warning. You should never use for loops to sum numerical elements from the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xm4Ve-s70h73",
    "outputId": "d68d003c-151e-4803-9823-5c8d1686fff3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q14.3 How many time slots that are warmer than 270, have weather main \"Clouds\"? 12133\n",
      "Q14.4 What is the minimum traffic volume of time slots captured on March 8th (all years), that was warmer than 290? 4780.0\n"
     ]
    }
   ],
   "source": [
    "# Using mask or .query syntax select rows/columns (int).\n",
    "# For working with dates, define helper functions that operate on the date_time string.\n",
    "\n",
    "# Q14.3 How many time slots that are warmer than 270, have weather main \"Clouds\"?\n",
    "print('Q14.3 How many time slots that are warmer than 270, have weather main \"Clouds\"?',db[db['temp']>270]['weather_main'].value_counts()['Clouds'])\n",
    "\n",
    "# Q14.4 What is the minimum traffic volume of time slots captured on March 8th (all years), that was warmer than 290?\n",
    "\n",
    "def divider_to_month_day(date):\n",
    "    res = date.split()\n",
    "    date_div = res[0].split('-')\n",
    "    return \"-\".join(date_div[-2:])\n",
    "\n",
    "res = db[(db['temp']>290)][['date_time','traffic_volume']] #returns a dataframe with date_time, traffic_volume column when temp>290\n",
    "res['date_time'] = res['date_time'].apply(divider_to_month_day) #transforms a date to month-day format\n",
    "print('Q14.4 What is the minimum traffic volume of time slots captured on March 8th (all years), that was warmer than 290?',\\\n",
    "      res[res['date_time'] == '03-08']['traffic_volume'].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTVitIYf0ib3",
    "outputId": "1300c6b6-032e-4497-ef1a-7b3c8497bf09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q15.3 What was the traffic volume of the highest amount of snow in one hour?\n",
      " 20158    5167.0\n",
      "20159    5167.0\n",
      "20160    5167.0\n",
      "20161    5167.0\n",
      "20270     888.0\n",
      "20271     888.0\n",
      "Name: traffic_volume, dtype: float64\n",
      "Q15.4 What is the median of temperatures captured in April 2017? 282.01\n"
     ]
    }
   ],
   "source": [
    "# Using mask or .query syntax select rows/columns and compute simple statistics (float)\n",
    "\n",
    "db.head()\n",
    "# Q15.3 What was the traffic volume of the highest amount of snow in one hour?\n",
    "max_snow = db['snow_1h'].max()\n",
    "print('Q15.3 What was the traffic volume of the highest amount of snow in one hour?\\n',db[db['snow_1h'] == max_snow]['traffic_volume'])\n",
    "\n",
    "# Q15.4 What is the median of temperatures captured in April 2017?\n",
    "\n",
    "def divider_to_year_month(date):\n",
    "    r = date.split()\n",
    "    date_div = r[0].split('-')\n",
    "    return \"-\".join(date_div[:-1])\n",
    "\n",
    "res = db.loc[:,['date_time',\"temp\"]]\n",
    "res['date_time'] = res['date_time'].apply(divider_to_year_month)\n",
    "print('Q15.4 What is the median of temperatures captured in April 2017?',res[res['date_time']=='2017-04']['temp'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fzig1HmlL4rq",
    "outputId": "9ebe4adf-0811-4acc-85e9-7907180880a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q16.1 What is the average temperature in celcius of the time slots with rainy_and_coudy=True?  13.584578809434692\n",
      "Q16.2 What is the average traffic volume on holidays?  2541.4371894960964\n",
      "Q16.3 What is the average traffic volume on non-holidays? 3281.497274534533\n",
      "Q16.4 What is the average traffic volume in the highest quantile? 5870.913350649351\n",
      "Q16.5 What is the average traffic volume in the lowest quantile? 485.5536195809998\n"
     ]
    }
   ],
   "source": [
    "# Using mask or .query syntax select rows/columns (float)\n",
    "\n",
    "# Q16.1 What is the average temperature in celcius of the time slots with rainy_and_coudy=True?\n",
    "print('Q16.1 What is the average temperature in celcius of the time slots with rainy_and_coudy=True? ',db[db['rainly_and_cloudy']==True]['temp_in_celcius'].mean())\n",
    "\n",
    "# Q16.2 What is the average traffic volume on holidays?\n",
    "print('Q16.2 What is the average traffic volume on holidays? ',db[db['is_holiday']==True]['traffic_volume'].mean())\n",
    "\n",
    "# Q16.3 What is the average traffic volume on non-holidays?\n",
    "print('Q16.3 What is the average traffic volume on non-holidays?',db[db['is_holiday']==False]['traffic_volume'].mean())\n",
    "\n",
    "# Q16.4 What is the average traffic volume in the highest quantile?\n",
    "print('Q16.4 What is the average traffic volume in the highest quantile?', db[db['traffic_cat']==5]['traffic_volume'].mean())\n",
    "\n",
    "# Q16.5 What is the average traffic volume in the lowest quantile?\n",
    "print('Q16.5 What is the average traffic volume in the lowest quantile?',db[db['traffic_cat']==1]['traffic_volume'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezvSnhPRfFXM"
   },
   "source": [
    "# 5. Basic date processing\n",
    "\n",
    "You figure out that column date is to harsh for you, so you decided to convert it to a more plausible format:\n",
    "\n",
    "- Use pandas method to_datetime() to convert the date to a good format.\n",
    "- Extract year, month, day and weekday from your new date column. Save them to separate columns.\n",
    "- How many columns has your data now?\n",
    "- Drop column date, remember to set inplace parameter to True.\n",
    "\n",
    "Hint: for datetime formatted date you could extract the year as follow:\n",
    "```\n",
    "data.date.dt.year\n",
    "```\n",
    "Very often date could be a ridiculously rich feature, sometimes it is holidays that matters, sometimes weekends, sometimes some special days like black friday.\n",
    "\n",
    "Learn how to work with date in Python!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ZghL5CmKTBZc"
   },
   "outputs": [],
   "source": [
    "# Create new columns based on `Captured` column\n",
    "# Q17.1 Convert date to datetime format\n",
    "\n",
    "db['date_time'] = pd.to_datetime(db['date_time'])\n",
    "\n",
    "# Q17.2 Extract and store `year`\n",
    "db['year'] = db['date_time'].dt.year\n",
    "\n",
    "# Q17.3 Extract and store `month`\n",
    "db['month'] = db['date_time'].dt.month\n",
    "\n",
    "# Q17.4 Extract and store `day`\n",
    "db['day'] = db['date_time'].dt.day\n",
    "\n",
    "# Q17.5 Extract and store `weekday` (Monday - 0, Sunday - 6)\n",
    "db['weekday'] = db['date_time'].dt.dayofweek\n",
    "# Q17.6 Extract and store `hour`\n",
    "db['hour'] = db['date_time'].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LrPCPd0fRYz"
   },
   "source": [
    "# 6. Groupby\n",
    "\n",
    "from the documentation https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html\n",
    "\n",
    "By “group by” we are referring to a process involving one or more of the following steps:\n",
    "\n",
    "- Splitting the data into groups based on some criteria.\n",
    "- Applying a function to each group independently.\n",
    "- Combining the results into a data structure.\n",
    "\n",
    "`.groupby()` is one of the most powerfull tool for feature engineering. Very often it is used to group object with the same categorical characteristics and compute some statistics (e.g. mean, max, etc.) of a their numerical characteric.\n",
    "\n",
    "Instead of computing average traffic volume with for each month you could compute average traffic volumes for every month in a single command:\n",
    "```\n",
    "data.groupby('month')['traffic_volume'].mean()\n",
    "```\n",
    "You could also make multi-column groups:\n",
    "```\n",
    "data.groupby(['weekday','month'])['traffic_volume'].min()\n",
    "```\n",
    "next, you could compute multiple aggregation functions:\n",
    "```\n",
    "data.groupby(['weekday','month'])['traffic_volume'].agg([min, max])\n",
    "```\n",
    "instead of using built-in functions you could compute custom functions using apply:\n",
    "```\n",
    "import numpy as np\n",
    "data.groupby(['weekday','month'])['traffic_volume'].apply(lambda x: np.quantile(x, .5))\n",
    "```\n",
    "and the coolest thing now is that you can map the results of groupby back on your DataFrame!\n",
    "```\n",
    "gp = data.groupby(['month'])['traffic_volume'].median()\n",
    "data['gp_feature'] = data['month'].map(gp)\n",
    "```\n",
    "Now, if some timeslot has month == 2, its gp_feature will be equal to the median traffic volume amongst all observations in February\n",
    "\n",
    "Read more examples in the documentation https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UU_wYcyETK9T",
    "outputId": "4869f3a1-0740-4830-e014-70e1da8ba8e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q18.2 What is the weekday with the lowest traffic volume? Sun\n",
      "Q18.3 What is the average traffic volume during months of September? 3301\n"
     ]
    }
   ],
   "source": [
    "# Find some date related information from the data (int)\n",
    "\n",
    "# Q18.2 What is the weekday with the lowest traffic volume?\n",
    "grouped = db.groupby('weekday')['traffic_volume'].mean()\n",
    "days = {0: 'Mon', 1:'Tue',2:'Wed',3:'Thu',4:'Fri',5:'Sat',6:'Sun'}\n",
    "print('Q18.2 What is the weekday with the lowest traffic volume?',days[grouped[grouped==grouped.min()].index[0]])\n",
    "\n",
    "# Q18.3 What is the average traffic volume during months of September?\n",
    "group_months = db.groupby(['month','year'])['traffic_volume'].mean()\n",
    "print('Q18.3 What is the average traffic volume during months of September?',int(group_months.loc[9].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "nRmmkfIVXp5K"
   },
   "outputs": [],
   "source": [
    "# Create some groupby features\n",
    "\n",
    "# Q19.1 `traffic_by_year` groupby `year` and compute median traffic volume.\n",
    "group = db.groupby('year')['traffic_volume'].median()\n",
    "db['traffic_by_year'] = db['year'].map(group)\n",
    "\n",
    "# Q19.2 `traffic_by_weekday` groupby `weekday` and compute median traffic volume.\n",
    "group = db.groupby('weekday')['traffic_volume'].median()\n",
    "db['traffic_by_weekday'] = db['weekday'].map(group)\n",
    "\n",
    "# Q19.3 `temperature_by_traffic` groupby `traffic_cat` and compute average temperature in celsius.\n",
    "group = db.groupby('traffic_cat')['temp_in_celcius'].mean()\n",
    "db['temp_by_traffic'] = db['traffic_cat'].map(group)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Y3IX6U1fOVI"
   },
   "source": [
    "# 7. Building a regression model\n",
    "\n",
    "- You do not need to normalize data for tree models, and for linear/knn models this step is essential.\n",
    "- Remember, that not all of the features in the table are numeric, some of them might be viewed as categorical.\n",
    "- You may create or drop any features you want - try to only keep features which you think will be relevant to the prediction of traffic volume.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "AwdbUu2wYKpB"
   },
   "outputs": [],
   "source": [
    "# Q20 Separate your data into inputs and targets, keeping only relevant inputs. Drop any features computed from the output eg. `traffic_cat`\n",
    "y = db[\"traffic_volume\"]\n",
    "num_features = ['temp','snow_1h','clouds_all','rain_1h']\n",
    "cat_features = ['weekday','is_holiday','hour']\n",
    "good_columns = [*num_features, *cat_features]\n",
    "X = db[good_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to split our data into train and test sets. Generally a random split is used, but one needs to be very careful with time series data - we need to make sure train and test data don't contain mixed adjacent time slots. In general with time series, it is recommended not to predict values from the past using input information from the future (although the applicability of this rule in our case is debatable), so we'll use sklearn's [TimeSeriesSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html) class here. TimeSeriesSplit splits data into a number of folds, then only provides data from past folds to train a model tested on the currently considered fold. So if we split our data into five parts, we'll get four folds:\n",
    "\n",
    "1. Train on [0], test on [1]\n",
    "2. Train on [0,1], test on [2]\n",
    "3. Train on [0, 1, 2], test on [3]\n",
    "4. Train on [0, 1, 2, 3], test on [4]\n",
    "\n",
    "For the following tasks, you are required to use train and test indices from the last fold provided by TimeSeriesSplit with `n_splits` = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hdLqDhuCYO1Z",
    "outputId": "99703cb2-7dc5-4987-cd29-7f1a149a2b57"
   },
   "outputs": [],
   "source": [
    "#### Q21 Split your data into train and test parts.\n",
    "# How many records (rows) do you have in train and test tables? (list of int)?\n",
    "# Use sklearn.model_selection.TimeSeriesSplit with n_splits=5\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, _ = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, _ = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "for train_index, test_index in tscv.split(X_train):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xqubzK5rYQA9",
    "outputId": "d9853eb1-2a3c-4eb2-e01a-aaceeb6d5b96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivang\\AppData\\Local\\Temp\\ipykernel_11012\\3644306324.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[num_features] = scaler.transform(X_train[num_features])\n",
      "C:\\Users\\ivang\\AppData\\Local\\Temp\\ipykernel_11012\\3644306324.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val[num_features] = scaler.transform(X_val[num_features])\n"
     ]
    }
   ],
   "source": [
    "# Create a predictive regression model of a traffic volume.\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Q22.2 Use decision tree regression\n",
    "tregressor = DecisionTreeRegressor()\n",
    "tregressor.fit(X_train, y_train)\n",
    "\n",
    "# Q22.1 Use linear regression with l2 regularization (Ridge regression)\n",
    "\n",
    "#Normalizing the data\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train[num_features])\n",
    "scaler.fit(X_val[num_features])\n",
    "\n",
    "X_train[num_features] = scaler.transform(X_train[num_features])\n",
    "X_val[num_features] = scaler.transform(X_val[num_features])\n",
    "\n",
    "#Building a baseline model\n",
    "ridge = Ridge(alpha=1)\n",
    "ridge.fit(X_train,y_train)\n",
    "\n",
    "# Q22.3 Use k nearest neighbours regression\n",
    "kregressor = KNeighborsRegressor(n_neighbors=15)\n",
    "kregressor.fit(X_train, y_train);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "7uWxRty0YSBd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17713944445335422\n",
      "{'alpha': 10.0}\n",
      "0.9457651530893113\n",
      "{'n_neighbors': 16}\n",
      "0.929904308965724\n",
      "{'max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "#### Use grid search to select optimal hyperparamters of your models. \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "\n",
    "scoring_func = make_scorer(r2_score)\n",
    "\n",
    "# Q23.1 Alpha for a ridge regression\n",
    "params = {'alpha':np.logspace(-6,1,20)} \n",
    "\n",
    "grid = GridSearchCV(estimator = ridge, param_grid = params, scoring = scoring_func)\n",
    "grid.fit(X_val, y_val)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "# Q23.3 Number of neighbours for the knn\n",
    "params = {'n_neighbors':np.arange(1,21,1)} \n",
    "\n",
    "grid = GridSearchCV(estimator = kregressor, param_grid = params, scoring = scoring_func)\n",
    "grid.fit(X_val, y_val)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "# Q23.2 Depth for the tree\n",
    "params = {'max_depth':np.arange(1,21,1)} \n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, _ = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, _ = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "for train_index, test_index in tscv.split(X_train):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "grid = GridSearchCV(estimator = tregressor, param_grid = params, scoring = scoring_func)\n",
    "grid.fit(X_val, y_val)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, test R^2 and MSE using decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE \n",
      "train: 202069.20724861618 \n",
      "test: 238261.26098174974\n",
      "\n",
      "R^2 \n",
      "train: PearsonRResult(statistic=0.974164018473302, pvalue=0.0) \n",
      "test: PearsonRResult(statistic=0.9688764449120182, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from scipy.stats import pearsonr as r\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "# Q24.2 Train, test MSE using decision tree regression\n",
    "tregressor = DecisionTreeRegressor(max_depth=8)\n",
    "tregressor.fit(X_train, y_train)\n",
    "print('MSE','\\ntrain:', mse(y_train,tregressor.predict(X_train)),'\\ntest:', mse(y_test,tregressor.predict(X_test))) \n",
    "\n",
    "# Q25.2 Train, test R^2 using decision tree regression\n",
    "print('\\nR^2','\\ntrain:', r(y_train,tregressor.predict(X_train)),'\\ntest:', r(y_test,tregressor.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, test R^2 and MSE using linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IVihHjlpYTrB",
    "outputId": "755e3cb5-acf6-4022-88a8-188cba883bef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE \n",
      "train: 3307375.16394213 \n",
      "test: 3248143.739105464\n",
      "\n",
      "R^2 \n",
      "train: PearsonRResult(statistic=0.40642667744209043, pvalue=0.0) \n",
      "test: PearsonRResult(statistic=0.40352223489829014, pvalue=3.00934945297e-312)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivang\\AppData\\Local\\Temp\\ipykernel_11012\\4270830596.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[num_features] = scaler.transform(X_train[num_features])\n",
      "C:\\Users\\ivang\\AppData\\Local\\Temp\\ipykernel_11012\\4270830596.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[num_features] = scaler.transform(X_test[num_features])\n"
     ]
    }
   ],
   "source": [
    " # Q24.1 Train, test MSE using linear regression with l2 regularization\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train[num_features])\n",
    "scaler.fit(X_test[num_features])\n",
    "\n",
    "X_train[num_features] = scaler.transform(X_train[num_features])\n",
    "X_test[num_features] = scaler.transform(X_test[num_features])\n",
    "\n",
    "ridge = Ridge(alpha=10)\n",
    "ridge.fit(X_train,y_train)\n",
    "\n",
    "print('MSE','\\ntrain:', mse(y_train,ridge.predict(X_train)),'\\ntest:', mse(y_test,ridge.predict(X_test)))\n",
    "print('\\nR^2','\\ntrain:', r(y_train,ridge.predict(X_train)),'\\ntest:', r(y_test,ridge.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, test R^2 and MSE using knn regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqwSIwVmYVZ6",
    "outputId": "c8bc2903-7def-4076-b7ba-b13cd2235b60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE \n",
      "train: 189242.10536959337 \n",
      "test: 215183.50478209442\n",
      "\n",
      "R^2 \n",
      "train: PearsonRResult(statistic=0.9758762039699833, pvalue=0.0) \n",
      "test: PearsonRResult(statistic=0.9721798146376979, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "# Q24.3 Train, test MSE using k nearest neighbours regression\n",
    "kregressor = KNeighborsRegressor(n_neighbors=20)\n",
    "kregressor.fit(X_train, y_train)\n",
    "print('MSE','\\ntrain:', mse(y_train,kregressor.predict(X_train)),'\\ntest:', mse(y_test,kregressor.predict(X_test)))\n",
    "\n",
    "# Q25.3 Train, test R^2 using k nearest neighbours regression\n",
    "print('\\nR^2','\\ntrain:', r(y_train,kregressor.predict(X_train)),'\\ntest:', r(y_test,kregressor.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1009.3594422295616, 'is_holiday')\n",
      "(908.7623361407143, 'temp')\n",
      "(297.31302514724695, 'snow_1h')\n",
      "(240.2219616765373, 'clouds_all')\n",
      "(159.9711234548191, 'weekday')\n"
     ]
    }
   ],
   "source": [
    "# Q26 Which features have largest (by absolute value) weight in your linear model (top 5 features)? (list of str).\n",
    "importances = sorted(zip(list(map(abs, ridge.coef_)), ridge.feature_names_in_), reverse = True)\n",
    "print(*importances[:5], sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9G_LlOHofTJp"
   },
   "source": [
    "# Make sure your .ipynb is linearly executable     \n",
    "# Kernel -> Restart & Run All -> No ERROR cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Homework1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
